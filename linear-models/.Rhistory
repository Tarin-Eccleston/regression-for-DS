# it's better to create new names entirely rather than extracting it from the data
office_header_names = expand.grid(x = c("concrete", "curtain-wall"),
y = "offices",
z = c("small", "medium", "large")) %>%
# create new names using a combination of the grid values
mutate(nn = paste(x, y, z, sep = "_")) %>%
pull(nn) # similar to $, get the values
# append other column names to clean_air_cond_df
names(clean_air_cond_df) = c("weather", "description", office_header_names)
View(clean_air_cond_df)
# append other column names to clean_air_cond_df
names(clean_air_cond_df) = c("weather", "description", "group", office_header_names)
# append other column names to clean_air_cond_df
# create group column
clean_air_cond_df = cbin(clean_air_cond_df(,1:2), empty_column=NA, clean_air_cond_df(3:,))
# append other column names to clean_air_cond_df
# create group column
clean_air_cond_df = cbin(clean_air_cond_df(,1:2), empty_column=NA, clean_air_cond_df(-1:2,))
# append other column names to clean_air_cond_df
# create group column
clean_air_cond_df = cbind(clean_air_cond_df(,1:2), empty_column=NA, clean_air_cond_df(-1:2,))
setwd("/Users/tarineccleston/Documents/Masters/STATS 765/statistical-learning-for-DS/w2")
library(tidyverse)
air_cond_df <- readxl::read_xlsx("data/simulation_outpu1_raw.xlsx", skip = 7, col_names = FALSE)
clean_air_cond_df = air_cond_df
# Step 1: Give sensible column names
# create column names for 6 measured cols
# use grid command when there is a combination of different header titles
# it's better to create new names entirely rather than extracting it from the data
office_header_names = expand.grid(x = c("concrete", "curtain-wall"),
y = "offices",
z = c("small", "medium", "large")) %>%
# create new names using a combination of the grid values
mutate(nn = paste(x, y, z, sep = "_")) %>%
pull(nn) # similar to $, get the values
# append other column names to clean_air_cond_df
# create group column
clean_air_cond_df = cbind(clean_air_cond_df(,1:2), empty_column=NA, clean_air_cond_df(-1:2,))
$add_column
?add_column
# append other column names to clean_air_cond_df
# create group column
clean_air_cond_df = add_column(clean_air_cond_df, 2)
View(clean_air_cond_df)
View(air_cond_df)
View(clean_air_cond_df)
# append other column names to clean_air_cond_df
# create group column
clean_air_cond_df = add_column(clean_air_cond_df, .after = 2)
View(clean_air_cond_df)
View(clean_air_cond_df)
# append other column names to clean_air_cond_df
# create group column
names(clean_air_cond_df) = c("weather", "description", "group", office_header_names)
View(clean_air_cond_df)
clean_air_cond_df = add_column(clean_air_cond_df, .before = "concrete_offices_small")
View(clean_air_cond_df)
clean_air_cond_df = add_column(clean_air_cond_df, "group" = NA, .before = "concrete_offices_small")
setwd("/Users/tarineccleston/Documents/Masters/STATS 765/statistical-learning-for-DS/w2")
library(tidyverse)
air_cond_df <- readxl::read_xlsx("data/simulation_outpu1_raw.xlsx", skip = 7, col_names = FALSE)
clean_air_cond_df = air_cond_df
# Step 1: Give sensible column names
# create column names for 6 measured cols
# use grid command when there is a combination of different header titles
# it's better to create new names entirely rather than extracting it from the data
office_header_names = expand.grid(x = c("concrete", "curtain-wall"),
y = "offices",
z = c("small", "medium", "large")) %>%
# create new names using a combination of the grid values
mutate(nn = paste(x, y, z, sep = "_")) %>%
pull(nn) # similar to $, get the values
# append other column names to clean_air_cond_df
# create group column
names(clean_air_cond_df) = c("weather", "description", office_header_names)
clean_air_cond_df = add_column(clean_air_cond_df, "group" = NA, .before = "concrete_offices_small")
View(clean_air_cond_df)
# defaults in the loop
group = "overall"
weather_value = "Very Hot Humid (Honolulu, HI)"
for(i in 1:nrows(clean_air_cond_df)) {
# replace NAs with the previous weather value
if(is.na(clean_air_cond_df(i,1))) {
clean_air_cond_df(i,1) = last_weather_value
} else {
weather_value = i
}
}
for(i in 1:nrow(clean_air_cond_df)) {
# replace NAs with the previous weather value
if(is.na(clean_air_cond_df(i,1))) {
clean_air_cond_df(i,1) = last_weather_value
} else {
weather_value = i
}
}
for(i in 1:nrow(clean_air_cond_df)) {
# replace NAs with the previous weather value
if(is.na(clean_air_cond_df[i,1))) {
# replace NAs with the previous weather value
if(is.na(clean_air_cond_df[i,1])) {
clean_air_cond_df(i,1) = last_weather_value
} else {
weather_value = i
}
View(clean_air_cond_df)
weather_value = "Very Hot Humid (Honolulu, HI)"
for(i in 1:nrow(clean_air_cond_df)) {
# replace NAs with the previous weather value
if(is.na(clean_air_cond_df[i,1])) {
clean_air_cond_df(i,1) = last_weather_value
} else {
weather_value = i
}
}
# defaults in the loop
group = "overall"
weather_value = "Very Hot Humid (Honolulu, HI)"
for(i in 1:nrow(clean_air_cond_df)) {
# replace NAs with the previous weather value
if(is.na(clean_air_cond_df[i,1])) {
clean_air_cond_df(i,1) = weather_value
} else {
weather_value = i
}
}
# defaults in the loop
group = "overall"
weather_value = "Very Hot Humid (Honolulu, HI)"
for(i in 1:nrow(clean_air_cond_df)) {
# replace NAs with the previous weather value
if(is.na(clean_air_cond_df[i,1])) {
clean_air_cond_df[i,1] = weather_value
} else {
weather_value = i
}
}
# replace NAs to string
clean_air_cond_df = replace_na(clean_air_cond_df, 'NA')
?replace_na
# replace NAs to string
clean_air_cond_df = replace_na(clean_air_cond_df, 'NA')
clean_air_cond_df[is.na(clean_air_cond_df)] = ""
clean_air_cond_df[is.na(clean_air_cond_df)] = ""
replace(clean_air_cond_df,is.na(clean_air_cond_df),"value to replace")
clean_air_cond_df[is.na(clean_air_cond_df),] <- 0
typeof(clean_air_cond_df)
typeof(clean_air_cond_df$weather)
clean_air_cond_df$weather %>% replace_na('none')
View(clean_air_cond_df)
clean_air_cond_df$weather = replace_na('none')
View(clean_air_cond_df)
air_cond_df <- readxl::read_xlsx("data/simulation_outpu1_raw.xlsx", skip = 7, col_names = FALSE)
clean_air_cond_df = air_cond_df
# Step 1: Give sensible column names
# create column names for 6 measured cols
# use grid command when there is a combination of different header titles
# it's better to create new names entirely rather than extracting it from the data
office_header_names = expand.grid(x = c("concrete", "curtain-wall"),
y = "offices",
z = c("small", "medium", "large")) %>%
# create new names using a combination of the grid values
mutate(nn = paste(x, y, z, sep = "_")) %>%
pull(nn) # similar to $, get the values
# append other column names to clean_air_cond_df
# create group column
names(clean_air_cond_df) = c("weather", "description", office_header_names)
clean_air_cond_df = add_column(clean_air_cond_df, "group" = NA, .before = "concrete_offices_small")
clean_air_cond_df$weather = replace_na('none')
View(clean_air_cond_df)
clean_air_cond_df = replace_na('none')
clean_air_cond_df = replace_na('none')
clean_air_cond_df = replace_na(clean_air_cond_df, 'none')
air_cond_df <- readxl::read_xlsx("data/simulation_outpu1_raw.xlsx", skip = 7, col_names = FALSE)
clean_air_cond_df = air_cond_df
# Step 1: Give sensible column names
# create column names for 6 measured cols
# use grid command when there is a combination of different header titles
# it's better to create new names entirely rather than extracting it from the data
office_header_names = expand.grid(x = c("concrete", "curtain-wall"),
y = "offices",
z = c("small", "medium", "large")) %>%
# create new names using a combination of the grid values
mutate(nn = paste(x, y, z, sep = "_")) %>%
pull(nn) # similar to $, get the values
# append other column names to clean_air_cond_df
# create group column
names(clean_air_cond_df) = c("weather", "description", office_header_names)
clean_air_cond_df = add_column(clean_air_cond_df, "group" = NA, .before = "concrete_offices_small")
clean_air_cond_df = replace_na(clean_air_cond_df, 'none')
air_cond_df <- readxl::read_xlsx("data/simulation_outpu1_raw.xlsx", skip = 7, col_names = FALSE)
clean_air_cond_df = air_cond_df
# Step 1: Give sensible column names
# create column names for 6 measured cols
# use grid command when there is a combination of different header titles
# it's better to create new names entirely rather than extracting it from the data
office_header_names = expand.grid(x = c("concrete", "curtain-wall"),
y = "offices",
z = c("small", "medium", "large")) %>%
# create new names using a combination of the grid values
mutate(nn = paste(x, y, z, sep = "_")) %>%
pull(nn) # similar to $, get the values
# append other column names to clean_air_cond_df
# create group column
names(clean_air_cond_df) = c("weather", "description", office_header_names)
clean_air_cond_df = add_column(clean_air_cond_df, "group" = NA, .before = "concrete_offices_small")
clean_air_cond_df = replace_na(clean_air_cond_df, list('single'))
View(clean_air_cond_df)
clean_air_cond_df = replace_na(clean_air_cond_df, list(weather = 'single'))
View(clean_air_cond_df)
clean_air_cond_df = replace_na(clean_air_cond_df, list(weather = "NA"))
# defaults in the loop
group = "overall"
weather_value = "Very Hot Humid (Honolulu, HI)"
for(i in 1:nrow(clean_air_cond_df)) {
# replace NAs with the previous weather value
if(clean_air_cond_df[i,1] == "NA") {
clean_air_cond_df[i,1] = weather_value
} else {
weather_value = i
}
}
View(clean_air_cond_df)
View(clean_air_cond_df)
setwd("/Users/tarineccleston/Documents/Masters/STATS 765/statistical-learning-for-DS/w2")
library(tidyverse)
air_cond_df <- readxl::read_xlsx("data/simulation_outpu1_raw.xlsx", skip = 7, col_names = FALSE)
clean_air_cond_df = air_cond_df
# Step 1: Give sensible column names
# create column names for 6 measured cols
# use grid command when there is a combination of different header titles
# it's better to create new names entirely rather than extracting it from the data
office_header_names = expand.grid(x = c("concrete", "curtain-wall"),
y = "offices",
z = c("small", "medium", "large")) %>%
# create new names using a combination of the grid values
mutate(nn = paste(x, y, z, sep = "_")) %>%
pull(nn) # similar to $, get the values
# append other column names to clean_air_cond_df
# create group column
names(clean_air_cond_df) = c("weather", "description", office_header_names)
clean_air_cond_df = add_column(clean_air_cond_df, "group" = NA, .before = "concrete_offices_small")
clean_air_cond_df = replace_na(clean_air_cond_df, list(weather = "NA"))
# defaults in the loop
group = "overall"
weather_value = "Very Hot Humid (Honolulu, HI)"
for(i in 1:nrow(clean_air_cond_df)) {
# replace NAs with the previous weather value
if(clean_air_cond_df[i,1] == "NA") {
clean_air_cond_df[i,1] = weather_value
} else {
weather_value = i
}
}
View(clean_air_cond_df)
for(i in 1:nrow(clean_air_cond_df)) {
# replace NAs with the previous weather value
if(clean_air_cond_df[i,1] == "NA") {
clean_air_cond_df[i,1] = weather_value
} else {
weather_value = i
}
}
setwd("/Users/tarineccleston/Documents/Masters/STATS 765/statistical-learning-for-DS/w2")
library(tidyverse)
air_cond_df <- readxl::read_xlsx("data/simulation_outpu1_raw.xlsx", skip = 7, col_names = FALSE)
clean_air_cond_df = air_cond_df
# Step 1: Give sensible column names
# create column names for 6 measured cols
# use grid command when there is a combination of different header titles
# it's better to create new names entirely rather than extracting it from the data
office_header_names = expand.grid(x = c("concrete", "curtain-wall"),
y = "offices",
z = c("small", "medium", "large")) %>%
# create new names using a combination of the grid values
mutate(nn = paste(x, y, z, sep = "_")) %>%
pull(nn) # similar to $, get the values
# append other column names to clean_air_cond_df
# create group column
names(clean_air_cond_df) = c("weather", "description", office_header_names)
x1 = as.data.frame(matrix(rep(NA, length(clean_air_cond_df)), nrow = 1))
names(x1) = names(clean_air_cond_df)
clean_air_cond_df_2 = bind_rows(x1, clean_air_cond_df) %>%
mutate(group = ifelse(is.na(description), "overall",
ifelse(description == "Sensible Cooling", "sensible_cooling",
ifelse(description == "Sensible Heating", "sensible_heating", NA))))
View(clean_air_cond_df_2)
# use zoo package for extra support
library(zoo)
group_vt = zoo(clean_air_cond_df$group)
View(clean_air_cond_df_2)
names(x1) = names(clean_air_cond_df)
clean_air_cond_df = bind_rows(x1, clean_air_cond_df) %>%
mutate(group = ifelse(is.na(description), "overall",
ifelse(description == "Sensible Cooling", "sensible_cooling",
ifelse(description == "Sensible Heating", "sensible_heating", NA))))
# use zoo package for extra support
library(zoo)
group_vt = zoo(clean_air_cond_df$group)
clean_air_cond_df$group = na.loc
group_vt = zoo(clean_air_cond_df$group)
clean_air_cond_df$group = na.locf(group_vt) # last observations carry forward (locf)
View(clean_air_cond_df_2)
View(clean_air_cond_df)
# remove non-informative rows, i.e rows with 6 value columns
num_na_per_row_vt = apply(clean_air_cond_df, 1, function(x) sum(is.na(x)))
clean_air_cond_df = clean_air_cond_df[which(num_na_per_row_vt<7),]
# fill "weather" NA values with previous non-na values
weather_vt = zoo(clean_air_cond_df$weather)
clean_air_cond_df$weather = na.locf(weather_vt) # last observations carry forward (locf)
forward(locf)
View(clean_air_cond_df)
# fill "weather" NA values with previous non-na values
weather_vt = zoo(clean_air_cond_df$weather)
clean_air_cond_df$weather = na.locf(weather_vt) # last observations carry forward (locf)
forward(locf)
clean_air_cond_df$weather = as.character(clean_air_cond_df$weather[1:length(clean_air_cond_df$weather)])
clean_air_cond_df$weather = na.locf(weather_vt) # last observations carry forward (locf)
clean_air_cond_df$weather = as.character(clean_air_cond_df$weather[1:length(clean_air_cond_df$weather)])
View(clean_air_cond_df)
View(clean_air_cond_df)
# fill "weather" NA values with previous non-na values
weather_vt = zoo(clean_air_cond_df$weather)
clean_air_cond_df$weather = na.locf(weather_vt) # last observations carry forward (locf)
# Step 3: Wrangle and Tidy the data
# gather operation
clean_air_cond_df = clean_air_cond_df %>%
gather(key = 'structure', value = 'value', -group, -weather, -description) %>%
seperate(structure, c("office_type", "office", "office_size"),
sep = "_") %>%
select(-office) # remove constant 'office' column as it's useless
d
d
d
d
# fill "weather" NA values with previous non-na values
weather_vt = zoo(clean_air_cond_df$weather)
clean_air_cond_df$weather = na.locf(weather_vt) # last observations carry forward (locf)
# Step 3: Wrangle and Tidy the data
# gather operation
clean_air_cond_df = clean_air_cond_df %>%
gather(key = 'structure', value = 'value', -group, -weather, -description) %>%
separate(structure, c("office_type", "office", "office_size"),
sep = "_") %>%
select(-office) # remove constant 'office' column as it's useless
View(clean_air_cond_df)
clean_air_cond_df %>% filter(office_size == 'small') %>%
filter(description == "Outdoor Temperature at Peak Load [C]"
& group == "sensible_cooling") %>% # view
ggplot(aes(x = weather, y = value, color = weather, shape = office_type)) +
geom_point(size = 3) +
theme(axis.text.x = element_text(angle = 60, hjust = 1),
legend.position = "right",
legend.text = element_text(size = 6),
legend.title = element_text(size = 8))
clean_air_cond_df %>% filter(office_size == 'small') %>%
filter(description == "Outdoor Temperature at Peak Load [C]"
& group == "sensible_cooling") %>% # view
ggplot(aes(x = weather, y = value, color = weather, shape = office_type)) +
geom_point(size = 3) +
theme(axis.text.x = element_text(angle = 60, hjust = 1),
legend.position = "right",
legend.text = element_text(size = 6),
legend.title = element_text(size = 8))
view(clean_air_cond_df)
head(clean_air_cond_df)
tinytex::install_tinytex()
Y
tinytex::install_tinytex()
setwd("/Users/tarineccleston/Documents/Masters/STATS 765/statistical-learning-for-DS/w4")
library(tidyverse)
library(Matrix)
data(aqaricus.train, package="xgboost")
table(agaricus.train$label)
install.packages('xgboost')
data(aqaricus.train, package="xgboost")
table(agaricus.train$label)
library(leasp)
library(leaps)
data(aqaricus.train, package="xgboost")
table(agaricus.train$label)
# create dataframe
x_y_df = data.frame(x = c(x),
y = c(y))
```{r}
set.seed(991) # replace "765" with your student ID.
n = 200
x = rnorm(n)
residual_std = exp(x) # error standard deviation is exponential w.r.t. x values,
y = 1.5+3*x + residual_std*rnorm(n)
set.seed(991) # replace "765" with your student ID.
n = 200
x = rnorm(n)
residual_std = exp(x) # error standard deviation is exponential w.r.t. x values,
y = 1.5+3*x + residual_std*rnorm(n)
### Step 1.2: Plot y vs. x and comment
```{r}
# create dataframe
x_y_df = data.frame(x = c(x),
y = c(y))
plot(y ~ x, data = )
plot(y ~ x, data = x_y_df)
# create dataframe
x_y_df = data.frame(cbind(x,y))
plot(y ~ x, data = x_y_df)
plot(y ~ x, xlab = "x", ylab = "y", data = x_y_df)
x_y_fit = lm(y ~ x, data = x_y_df)
x_y_fit = lm(y ~ x, data = x_y_df)
abline(coef(x_y_fit)[1], coef(x_y_fit)[2])
plot.new
abline(coef(x_y_fit)[1], coef(x_y_fit)[2])
plot(y ~ x, xlab = "x", ylab = "y", data = x_y_df)
abline(coef(x_y_fit)[1], coef(x_y_fit)[2])
setwd("/Users/tarineccleston/Documents/Masters/STATS 762/regression-for-DS/linear-models")
catheter.df <- read.table("data/catheter.data", header = TRUE)
# Fit a linear model.
catheter.fit <- lm(ca ~ ht, data = catheter.df)
# Std. Error`: The `std` of coefficients if we repeat the sampling from the population infinite times.
summary(catheter.fit)
# MUST Label Axis
plot(ca ~ ht, data = catheter.df, xlab = "Height (inches)", ylab = "Catheter Lenght (inches)")
abline(coef(catheter.fit)[1], coef(catheter.fit)[2])
set.seed(991) # replace "765" with your student ID.
n = 200
x = rnorm(n)
residual_std = exp(x) # error standard deviation is exponential w.r.t. x values,
y = 1.5+3*x + residual_std*rnorm(n)
set.seed(991) # replace "765" with your student ID.
n = 200
x = rnorm(n)
residual_std = exp(x) # error standard deviation is exponential w.r.t. x values,
y = 1.5+3*x + residual_std*rnorm(n)
### Step 1.2: Plot y vs. x and comment
```{r}
# create dataframe
x_y_df = data.frame(cbind(x,y))
plot(y ~ x, xlab = "x", ylab = "y", data = x_y_df)
# create dataframe
x_y_df = data.frame(cbind(x,y))
plot(y ~ x, xlab = "x", ylab = "y", data = x_y_df)
```{r}
## Task 2: Fit the linear regression model as usual
### Step 2.1: Fit a linear regression model
Fit a linear regression model y~x and generate the model summary output.
```{r}
x_y_fit = lm(y ~ x, data = x_y_df)
plot(y ~ x, xlab = "x", ylab = "y", data = x_y_df)
abline(coef(x_y_fit)[1], coef(x_y_fit)[2])
x_y_fit = lm(y ~ x, data = x_y_df)
plot(y ~ x, xlab = "x", ylab = "y", data = x_y_df)
abline(coef(x_y_fit)[1], coef(x_y_fit)[2])
summary(x_y_fit)
What is the standard error of coefficient of X? What is the 95% confidence interval of the Î²1^
confint(x_y_fit)
# get the sandwich variance estimator
y = matrix(y,ncol = 1)
library(sandwich)
# get the sandwich variance estimator
y = matrix(y,ncol = 1)
View(y)
x = cbind(1,matrix(x,ncol=1))
# get the sandwich variance estimator
# use the matrix DS for matrix multiplication
y_mat = matrix(y,ncol = 1)
x_mat = cbind(1,matrix(x,ncol=1))
# variance / covariance matrix
vcovHC(x_y_fit, type = "HC")
# get the sandwich variance estimator
# use the matrix DS for matrix multiplication
y_mat = matrix(y,ncol = 1)
x_mat = cbind(1,matrix(x,ncol=1))
# sandwich estimator
solve(t(x_mat) %*% x_mat) %*% t(x_mat) diag(diag((y-fitted(x_y_fit)) %*%
# compare sandwich vs lm for coefficients
summary(x_y_fit)$coef
# variance / covariance matrix
# calculating automatically
vcovHC(x_y_fit, type = "HC")
# compare sandwich vs lm for coefficients
sqrt(diag(vcov(x_y_fit)))
# compare sandwich vs lm for coefficients
vconv(x_y_fit)
# compare sandwich vs lm for coefficients
vcov(x_y_fit)
# variance / covariance matrix
# calculating automatically
vcovHC(x_y_fit, type = "HC")
# compare sandwich vs lm for coefficients
# lm
vcov(x_y_fit)
# calculating SE using sandwich estimator
sqrt(diag(vcovHC(x_y_fit)))
# calculating SE using lm under EOV assumption
sqrt(diag(vcov(x_y_fit)))
# variance / covariance matrix
# calculating automatically
vcovHC(x_y_fit, type = "HC")
# calculating SE using sandwich estimator
sqrt(diag(vcovHC(x_y_fit)))
sandwich_se = sqrt(diag(vcovHC(x_y_fit)))[2]
coef(x_y_fit) - qnorm(0.975) * sandwich_se
p-value = 2 * (1-pt(t_stat), df = n-2, lower.tail = TRUE))
p-value = 2 * (1-pt(t_stat, df = n-2, lower.tail = TRUE))
t_stat = coef(x_y_fit)/sandwich_se
p-value = 2 * (1-pt(t_stat, df = n-2, lower.tail = TRUE))
sandwich_se = sqrt(diag(vcovHC(x_y_fit)))[2]
t_stat = coef(x_y_fit)/sandwich_se
p-value = 2 * (1-pt(t_stat, df = n-2, lower.tail = TRUE))
t_stat
p_value = 2 * (1-pt(t_stat, df = n-2, lower.tail = TRUE))
p_value
summary(x_y_fit)$coef

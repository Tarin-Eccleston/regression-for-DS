catheter.df <- read.table("catheter.data", header = TRUE)
catheter.fit <- lm(ca ~ ht, data = catheter.df)
summary(catheter.fit)
# MUST Label Axis
plot(ca ~ ht, data = catheter.df, xlab = "Height (inches)", ylab = "Catheter Lenght (inches)")
abline(coef(catheter.fit)[1], coef(catheter.fit)[2])
source("~/Documents/Masters/STATS 762/Exercises/Catheter Analysis/catheter_analysis.R")
setwd("/Users/tarineccleston/Documents/Masters/STATS 762/Exercises/Catheter Analysis")
catheter.df <- read.table("catheter.data", header = TRUE)
catheter.fit <- lm(ca ~ ht, data = catheter.df)
summary(catheter.fit)
# MUST Label Axis
plot(ca ~ ht, data = catheter.df, xlab = "Height (inches)", ylab = "Catheter Lenght (inches)")
abline(coef(catheter.fit)[1], coef(catheter.fit)[2])
crabs.df <- read.table("crab.data", header = TRUE)
plot(sats ~ weight, data = crabs.df)
crabs.fit <- glm(sats ~ weight, data = crabs.df, family = "poisson")
summary(crabs.df)
xx <- seq(0, 6, length.out = 100)
yy <- predict(crabs.df, newdata = data.frame(weight = xx), type = "response")
lines(xx, yy)
chd.df <- read.table("chd.data", header = TRUE)
chd.fit <- glm(chd ~ age, family = "binomial", data = chd.df)
summary(chd.fit)
plot(chd ~ age, data = chd.df)
xx <- seq(10, 80, length.out = 1000)
yy <- predict(chd.fit, newdata = data.frame(age = xx), type = "response")
lines(xx, yy)
chd.df <- read.table("chd.data", header = TRUE)
chd.fit <- glm(chd ~ age, family = "binomial", data = chd.df)
summary(chd.fit)
plot(chd ~ age, data = chd.df)
xx <- seq(min(chd.df$age), max(chd.df$age), length.out = 1000)
yy <- predict(chd.fit, newdata = data.frame(age = xx), type = "response")
lines(xx, yy)
crabs.df <- read.table("crab.data", header = TRUE)
plot(sats ~ weight, data = crabs.df)
# Use linear regression. Poisson regression is most suitable in this case.
# The expected value must be above 0, so linear regression doesn't give meaningful prediction sometimes.
crabs.fit <- lm(sats ~ weight, data = crabs.df)
plot(sats ~ weight, data = crabs.df)
abline(crabs.fit$coefficients[1], crabs.fit$coefficients[2])
# Poisson regression
crabs.logfit <- glm(sats ~ weight, data = crabs.df, family = "poisson")
# We cannot plot curve in R, so use sequence.
xx <- seq(min(crabs.df$weight), max(crabs.df$weight), length.out = 101)
# The linear predictor gives log of mew. Log being the link function. To get mew, don't need to exponentiate, specify type as response.
yy <- predict(crabs.logfit, newdata = data.frame(weight = xx), type = 'response')
plot(sats ~ weight, data = crabs.df)
lines(yy ~ xx)
chd.fit <- glm(chd ~ age, family = "binomial", data = chd.df)
summary(chd.fit)
plot(chd ~ age, data = chd.df)
xx <- seq(10, 80, length.out = 1000)
yy <- predict(chd.fit, newdata = data.frame(age = xx), type = "response")
lines(xx, yy)
# Create new matrix, age from sample, and predicted likelihood of chd to the response
cbind(chd.df$age, fitted(chd.fit))
# flipping "coin" for each person from age 20 -> 63
n.people <- nrow(chd.df)
new.chd <- rbinom(n.people, 1, predict(chd.fit, type = "response"))
par(mfrow = c(1, 2))
plot(chd ~ age, data = chd.df, main = "Original")
yy <- predict(chd.fit, newdata = data.frame(age = xx), type = "response")
lines(xx, yy)
plot(new.chd ~ age, data = chd.df, main = "Simulated")
new.fit <- glm(new.chd ~ age, family = binomial("probit"), data = chd.df)
yy <- predict(new.fit, newdata = data.frame(age = xx), type = "response")
lines(xx, yy)
git
git init
n.boots <- 1000
coef.boot <- matrix(0, nrow = n.boots, ncol = 2)
agep80.boot <- numeric(n.boots)
for (i in 1:n.boots){
chd.boot <- rbinom(n.people, 1, predict(chd.fit, type = "response"))
fit.boot <- glm(chd.boot ~ age, type = "binomial", data = chd.df)
coef.boot[i, ] <- coef(fit.boot)
agep80.boot[i] <- (0.84162 - coef(fit.boot)[1])/coef(fit.boot)[2]
}
n.boots <- 1000
coef.boot <- matrix(0, nrow = n.boots, ncol = 2)
agep80.boot <- numeric(n.boots)
for (i in 1:n.boots){
chd.boot <- rbinom(n.people, 1, predict(chd.fit, type = "response"))
fit.boot <- glm(chd.boot ~ age, family = "binomial", data = chd.df)
coef.boot[i, ] <- coef(fit.boot)
agep80.boot[i] <- (0.84162 - coef(fit.boot)[1])/coef(fit.boot)[2]
}
summary(fit.boot)
apply(coef.boot, 2, sd)
git help
setwd("/Users/tarineccleston/Documents/Masters/STATS 762/regression-for-DS/information-criteria")
X <- read.csv("data/X.csv", header = TRUE)
pairs(X)
# 2)
y = 10 + 1*X.X1
# 2)
y = 10 + 1*X$X1
mu = beta_true[1] + beta_true[2]*X$X1 + beta_true[3]*X$X2 + beta_true[4]*X$X1*X$X2
beta_true = [10, 2, 3, 1]
sigma = 4
mu = beta_true[1] + beta_true[2]*X$X1 + beta_true[3]*X$X2 + beta_true[4]*X$X1*X$X2
beta_true = c[10, 2, 3, 1]
beta_true = c(10, 2, 3, 1)
sigma = 4
mu = beta_true[1] + beta_true[2]*X$X1 + beta_true[3]*X$X2 + beta_true[4]*X$X1*X$X2
$mean
mean_mu = mean(mu)
rnorm(nrow(X), mean_mu, 4)
X$Y
X$Y = Y
# 50 simulations of the normal distribution
Y =
X$Y = rnorm(nrow(X), mean_mu, 4)
# 50 simulations of the normal distribution
Y =
X$Y = rnorm(nrow(X), mu, 4)
pairs(X)
beta_true = c(10, 2, 3, 1)
sigma = 4
# generate regression line based on the given "true" parameters
mu = beta_true[1] + beta_true[2]*X$X1 + beta_true[3]*X$X2 + beta_true[4]*X$X1*X$X2
# simulate of the normal distribution
X$Y = rnorm(nrow(X), mu, 4)
pairs(X)
# 3)
model = lm(X$Y ~ X$X1*X$X2, data = X)
# 3)
model = lm(Y ~ X1*X2, data = X)
summary(model)
summary(model).coef
summary(model)$coef
summary(model)$coef[,[1]]
summary(model)$coef[[1]]
summary(model)$coef[[1],]
summary(model)$coef[1]
summary(model)$coef[1,]
summary(model)$coef[,1]
beta_hat = summary(model)$coef[,1]
summary(model)
install MuMIn
install.packages(MuMIn)
confint(model,"X1", level=0.95)
beta_hat = summary(model)$coef[,1]

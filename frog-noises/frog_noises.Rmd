# STATS 762: Assignment 2
## Author: Tarin Eccleston

### Q1a)

```{r}
setwd("/Users/tarineccleston/Documents/Masters/STATS 762/regression-for-DS/frog-noises")
library(tidyverse)
library(MuMIn)


frog_df = read.csv("data/frogs.csv")
# find the absolute distance between the frog and each microphone
frog_df$distance = sqrt((abs(frog_df$mic.x - frog_df$animal.x)^2) + (abs(frog_df$mic.y - frog_df$animal.y)^2))
# get the probability of that particular microphone detected that particular frog
# based on the number of calls the frog makes and the detected amount from the mic
frog_df$prob = frog_df$detected / frog_df$n.calls
```

```{r}
pairs(frog_df[,c(1,7,8,9,10)])
```


```{r}
# fit model
frog_fit <- glm(cbind(detected, n.calls - detected) ~ distance, family = "binomial", data = frog_df)

summary(frog_fit)
xx <- seq(min(frog_df$distance), max(frog_df$distance), length.out = 1000)
yy <- predict(frog_fit, newdata = data.frame(distance = xx), type = "response")

{plot(frog_df$distance, frog_df$prob, col = c(1:7)[frog_df$mic.id], main = "Distance of Frog from Mic vs Probability of Noise Detection", xlab = "Distance of Frog from Mic (m)", ylab = "Probability of Noise Detection")
legend('topright', legend = c("1","2","3","4","5","6","7"), col = c(1:7), pch = 1)
lines(xx, yy)}
```

### Q1b)

Looking at the data, it appears that the technical mishaps appear to be for some observations of frog noises recorded 0 - 4 meters away from the frog, where the probability of the call detection of the frogs is 0. This is unusual in comparison to other similar distance values in the data as those observations have a probability of detecting calls close to 1. We will do further analysis on this...


```{r}
plot(frog_fit, which=1:6)
```

The residuals vs fitted shows a non constant variance in a data, is worth mentioning but shouldn't be an issue as we are making an inference, not point predictions.

The QQ plot shows a non-normal error distribution with a symmetric short tail. We can ignore this as in most cases, the sampling distribution of the betas will be adequately approximated by the normal distribution.

As shown from the Cook's distance plot, observations 24, 157, and 143 appear to be influential as they're above 1. 

As shown in the Residuals vs Leverage plot, observations 24, 157, and 143 are located approximately on the bottom right hand corner. These points appear to be both moderately leveraged and outlier (high residual) observations making them influential points.

Let's take a look at which mic these observations were taken from...

```{r}
mic_obs_24 = frog_df[24,]$mic.id 
mic_obs_143 = frog_df[143,]$mic.id 
mic_obs_157 = frog_df[157,]$mic.id

influential_mic_obs = cbind(mic_obs_24, mic_obs_143, mic_obs_157)
rownames(influential_mic_obs) = 'mic.id'
influential_mic_obs
```

All influential observations appear to come from mic 3. Let's look at all observations 
from mic 3

```{r}
mic_3 = frog_df %>%
  filter(mic.id == 3) %>%
  select(mic.id, animal.id, distance, detected, n.calls)
mic_3
```

Mic 3 fails to detect all frog calls for a range of distances from the mic to the frog
This is unexpected, as other mics are able to pickup calls when the frog is close to the the mic. We can assume that observations from mic 3 are untrustworthy as the mic is faulty or didn't record properly.

### Q2a) b)

Remove all observations which were recorded from mic 3. Since mic 3 is assumed to give
incorrect measurements. We assume that the residuals are normally distributed in regression. If some of the measurements are wrong, it can violate this assumption and lead to biased and inefficient estimates of the regression coefficients.

```{r}
# remove mic 3 observations
frog_corrected_df = frog_df %>%
  filter(mic.id != 3)

frog_corrected_df$mic.id = as.factor(frog_corrected_df$mic.id)

# fit model again and show improvement in fit
frog_corrected_fit <- glm(cbind(detected, n.calls - detected) ~ distance, family = "binomial", data = frog_corrected_df)

summary(frog_corrected_fit)
xx <- seq(min(frog_corrected_df$distance), max(frog_corrected_df$distance), length.out = 1000)
yy <- predict(frog_corrected_fit, newdata = data.frame(distance = xx), type = "response")

{plot(frog_corrected_df$distance, frog_corrected_df$prob, col = c(1:7)[frog_corrected_df$mic.id], main = "Distance of Frog from Mic vs Probability of Noise Detection", xlab = "Distance of Frog from Mic (m)", ylab = "Probability of Noise Detection")
legend('topright', legend = c("1","2","3","4","5","6","7"), col = c(1:7), pch = 1)
lines(xx, yy)}
```

```{r}
plot(frog_corrected_fit, which=1:6)
```

New model with mic 3 data removed appears to still have non constant variance on the residual vs fitted graph.

The QQ plot shows greater normality after removing observations from mic 3, however the plot still shows a non-normal error distribution with a symmetric short tail. We can ignore this as in most cases, the sampling distribution of the betas will be adequately approximated by the normal distribution.

As shown from the Cook's distance plot, observations 23, 37, and 58 appear to be most influential, however they're much below 1. 

As shown in the Residuals vs Leverage plot, observations 23, 37, and 58 all appear to be somewhat outliers with a high residual, making them somewhat influencial. Let's investigate further...

```{r}
mic_obs_23 = frog_corrected_df[23,]$mic.id 
mic_obs_37 = frog_corrected_df[37,]$mic.id 
mic_obs_58 = frog_corrected_df[58,]$mic.id

influential_mic_obs = cbind(mic_obs_23, mic_obs_37, mic_obs_58)
rownames(influential_mic_obs) = 'mic.id'
influential_mic_obs
```

All observations appear to come from random mics. We can infer that these influential points are due to chance, unlike measurements from mic 3 which were untrustworthy as mic 3 was faulty. We keep these points in our model.

Now lets try explaining the probability based on distance, animal ID and mic ID. We will try all possible models using dredge with AIC penalty. 

```{r}
# remove multicollinear variables such as mic and frog coordinates used
# to calculate absolute distance
frog_corrected_2_df = frog_corrected_df %>%
  select(animal.id, mic.id, distance, detected, n.calls)

# treat each mic and animal as a factor so we can compare between categories
frog_corrected_2_df$mic.id = as.factor(frog_corrected_2_df$mic.id)
frog_corrected_2_df$animal.id = as.factor(frog_corrected_2_df$animal.id)

# use mic.id and animal.id as explanatory variables
# use exhaustive search methods (AIC) so we don't miss anything
frog_corrected_2_fit <- glm(cbind(detected, n.calls - detected) ~ ., family = "binomial", data = frog_corrected_2_df)
summary(frog_corrected_2_fit)
```

Distance and mic ID seem the most statistically significant compared to animal ID from the summary table above.

```{r}
options(na.action = "na.fail")
all_fit = dredge(frog_corrected_2_fit)
head(all_fit)
```
```{r}
plot(all_fit,col="blue")
```

Models 7, with 7 degrees of freedom seems to perform the best with the lowest AIC. This takes mic 1 as the baseline, and other mic coefficients in comparison with mic 1 and the respective mic. Model 3 follows behind it, with using only
distance to explain probability of detecting a call.

```{r}
best_model = get.models(all_fit, 1)[[1]]
summary(best_model)
```

Frogs all produce calls at about the same volume. We wouldnâ€™t expect some frogs to be more detectable than others based on the characteristics of its call, this explains why we a relatively high p-value for the animal.id factors, and why models which used animal-id in dredge were heavily penalised and are not used in our final model.

As the low p-values suggest for each of the mic.id coefficients, there is a clear difference in frog noise measurement performance between each mic and the baseline (mic 1). This could be due to some microphones being better at detecting calls than others: one placed inside a bush might be less sensitive to frog noises compared to one placed out in the open. 

```{r}
frog_final_fit = glm(cbind(detected, n.calls - detected) ~ distance + mic.id, family = "binomial", data = frog_corrected_df)
xx = seq(min(frog_corrected_df$distance), max(frog_corrected_df$distance), length.out = 1000)

mic_1 = predict(frog_final_fit, newdata = data.frame(distance = xx, mic.id = "1"), type = "response")
mic_2 = predict(frog_final_fit, newdata = data.frame(distance = xx, mic.id = "2"), type = "response")
mic_4 = predict(frog_final_fit, newdata = data.frame(distance = xx, mic.id = "4"), type = "response")
mic_5 = predict(frog_final_fit, newdata = data.frame(distance = xx, mic.id = "5"), type = "response")
mic_6 = predict(frog_final_fit, newdata = data.frame(distance = xx, mic.id = "6"), type = "response")
mic_7 = predict(frog_final_fit, newdata = data.frame(distance = xx, mic.id = "7"), type = "response")

{plot(frog_corrected_df$distance, frog_corrected_df$prob, col = c(1:2,4:7)[frog_corrected_df$mic.id], main = "Distance of Frog from Mic vs Probability of Noise Detection", xlab = "Distance of Frog from Mic (m)", ylab = "Probability of Noise Detection")
lines(xx, mic_1, col = 1)
lines(xx, mic_2, col = 2)
lines(xx, mic_4, col = 4)
lines(xx, mic_5, col = 5)
lines(xx, mic_6, col = 6)
lines(xx, mic_7, col = 7)
legend('topright', legend = c("mic 1","mic 2","mic 4","mic 5","mic 6","mic7"), col = c(1:2, 4:7), pch = 1)}
```

Furthermore we can see a clear difference of detection performance between each mic.

```{r}
plot(frog_final_fit, which=1:6)
```
All diagnostic plots look the same.

Validate model using deviance lack of fit test

```{r}
1-pchisq(frog_final_fit$deviance, frog_final_fit$df.residual)
```

At 0.999, the observed deviance statistic is not extreme under the null hypothesis, and there is strong evidence that the fitted model is a good fit for the data.

Therefore, we can conclude that the detection function is the following...

`log(odds-ratio) = beta_0_hat + beta_1_hat * distance + beta_2_hat * mic_id2 + beta_4_hat * mic_id4 + beta_5_hat * mic_id5 + beta_6_hat * mic_id6 + beta_7_hat * mic_id7`

where `mic_id` is a categorical factor

where `Probability of Success = odds-ratio / (1 + odds-ratio)`

```{r}
exp(summary(frog_final_fit)$coeff["distance","Estimate"])
```


Calculating the odds ratio shows that the probability of detection decreases by 26% for every meter further away the frog is from the microphone. Additionally for a frog at a fixed distance away from a microphone, the log probability increases or decreases depending on which microphone it is.

Going back onto our question, we want to be able to fit a model that estimates the effect of distance between a frog and a microphone on the probability that a call produced by the frog is detected by the microphone. This basically is a detection function. If we were to factor in the mic ID as an explanatory variable, this will highly depend on the placement for each mic, which means that the model generated from each mic for this dataset would be biased towards to this sample and not generalised for say, new sampled data. If we wanted to measure the detection for this particular sample, we keep the mic.id term, if we wanted a more generalised solution for further field use, we would drop the mic ID terms and just use distance to explain probability of detecting a frog call, this should give similar performance.
